---
layout: full-width
title: "AI and LLM Usage Guidelines"
description: "Guidelines for responsible and transparent use of AI and Large Language Models (LLMs) by Google Summer of Code contributors."
permalink: /initiatives/gsoc/gsoc_ai_usage_guidelines
tags: gsoc, llm, ai, guideline
---

# LLM Usage

## NOTE

⚠️  Failure to disclose LLM usage or submission of unreviewed AI-generated content **may result in proposal dismissal** from GSoC without further review ⚠️ 

## Purpose

This document establishes guidelines for the responsible and transparent use of **AI and Large Language  Models (LLMs)** (e.g., ChatGPT, Gemini, Claude, Copilot, etc) by **Google Summer of Code (GSoC)** contributors working on OWASP projects.

The intent of this guideline is to support learning and productivity while preserving originality, accountability, and open-source integrity.

---

## 1. Acceptable Use

Contributors **may use LLMs** for supportive tasks, including:

- Improving clarity, grammar, or structure of documentation or reports
- Assisting with code comments, summaries, or test-case generation
- Learning and exploration, provided outputs are independently reviewed and understood

LLMs **must not** be used to automatically generate substantial portions of code, documentation, designs, or research outputs **without full review and acknowledgment** by the contributor.

All final submissions must reflect the contributor's own understanding, decision-making, and work.

---

## 2. Disclosure Requirement

If an LLM was used in any part of a proposal, report, or project artifact, contributors **must include** a section titled **"LLM Usage Considerations"**.

This section should:

- Describe **how and why** an LLM was used  
  (e.g., proofreading documentation, suggesting variable names)
- Confirm that all generated content was **independently reviewed, tested, and verified**
- Include the following statement:

> LLMs were used for supportive or editorial purposes in this work. All outputs were reviewed and validated by the contributor to ensure accuracy and originality.

Failure to include this disclosure when applicable is considered a guidelines violation.

---

## 3. Core Principles

### Originality

Contributors are fully responsible for the **originality, correctness, and integrity** of all submitted work, including code, documentation, and designs.

All dependencies, datasets, and external content must be properly credited and comply with applicable open-source licenses.

---

### Transparency

If an LLM materially influenced a design decision, code snippet, experiment, or analysis, the contributor must:

- Clearly explain the role of the model
- Validate the correctness of the output
- Mark outputs from closed-source or non-reproducible LLMs as **non-reproducible**

---

### Responsibility

Contributors and mentors must use LLMs ethically and responsibly:

- Do not include copyrighted, confidential, or proprietary material in prompts
- Respect user-data privacy and intellectual-property rights
- Consider environmental impact when using or fine-tuning models  
  (e.g., prefer smaller models or shared infrastructure when possible)

---

## 4. Enforcement

- Failure to disclose LLM usage or submission of unreviewed AI-generated content **may result in proposal dismissal** from GSoC without further review
- Contributors are strongly encouraged to discuss LLM usage early with mentors to ensure transparency and alignment with project expectations

---

## 5. Continuous Review

Generative-AI technologies evolve rapidly. Contributors and mentors should raise questions about unclear or borderline cases with program administrators or organization leads **before submission**.

The guidelines may be updated to reflect changes in tooling, expectations, or program requirements.

---